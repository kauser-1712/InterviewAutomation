{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automating Interviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing requisities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain google-generativeai pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, List, Optional, Any\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from PIL import Image\n",
    "import os\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json\n",
    "import fitz  \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalInfo(BaseModel):\n",
    "    name: str = Field(None, description='Name of the candidate')\n",
    "    email: str = Field(None, description='Email ID of the candidate')\n",
    "    phone: str = Field(None, description='Contact number of the candidate')\n",
    "    address: str = Field(None, description='Location (city or state)')\n",
    "\n",
    "class Education(BaseModel):\n",
    "    institution: str = Field(None, description='Name of school, college, or university')\n",
    "    degree: str = Field(None, description='Degree obtained (e.g., Bachelor’s, Master’s, etc.)')\n",
    "    field_of_study: str = Field(None, description='Major or field of study')\n",
    "    start_date: str = Field(None, description='Start date of the course (format: YYYY-MM)')\n",
    "    end_date: str = Field(None, description='End date of the course (format: YYYY-MM)')\n",
    "\n",
    "class Experience(BaseModel):\n",
    "    organization: str = Field(None, description='Name of the company')\n",
    "    role: str = Field(None, description='Position at the company')\n",
    "    responsibilities: str = Field(None, description='Projects or work description')\n",
    "\n",
    "class Project(BaseModel):\n",
    "    title: Optional[str] = Field(None, description='Title of the project')\n",
    "    outcome: Optional[str] = Field(None, description='Result or outcome of the project')\n",
    "    approach: Optional[str] = Field(None, description='Methodology or approach used in the project')\n",
    "\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    personal_info: PersonalInfo = Field(None, description='Personal details of the candidate')\n",
    "    educational_qualifications:List[Education] = Field(default_factory=list, description='List of educational qualifications')\n",
    "    skills: List[str] = Field(description='List of skills relevant to the candidate’s expertise')\n",
    "    projects: List[Project] = Field(description='List of projects the candidate has worked on')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing model\n",
    "model = ChatGoogleGenerativeAI(model='gemini-2.0-flash')\n",
    "\n",
    "# pydantic parser\n",
    "parser = PydanticOutputParser(pydantic_object=Resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Parsing - Image as Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\"\n",
    "Job Responsibilities:\n",
    "Algorithm Development: Assist in the design, implementation, and testing of machine learning models to improve and extend our AI tools.\n",
    "Data Analysis: Participate in the collection, cleaning, and analysis of data to inform model adjustments and new feature development.\n",
    "Research: Stay abreast of the latest advancements in machine learning and data science, suggesting applications for new technologies and methodologies within our projects.\n",
    "Collaboration: Work closely with our AI and product teams to integrate machine learning models seamlessly into our platform, enhancing user experience and product value.\n",
    "Performance Monitoring: Monitor the performance of our AI tools, conducting rigorous testing and making recommendations for enhancements based on your findings.\n",
    "Innovation: Contribute to brainstorming sessions aimed at identifying new opportunities for AI application within our services.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"personal_info\": {},\n",
      "    \"educational_qualifications\": [],\n",
      "    \"skills\": [\n",
      "        \"Programming: Python, R, SQL\",\n",
      "        \"Machine Learning\",\n",
      "        \"Deep Learning\",\n",
      "        \"Natural Language Processing\",\n",
      "        \"Big Data: Spark\",\n",
      "        \"Data Handling: Web Scraping, Data Manipulation\",\n",
      "        \"Statistics: Hypothesis Testing, Regression Analysis\"\n",
      "    ],\n",
      "    \"most_relevant_project\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# loading images and encoding\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "# prompt template\n",
    "resume_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the resume information in structured JSON format as per the provided schema.\\n'{format_instructions}'\\n\"),\n",
    "    (\"human\", [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Extract structured resume data from this image.\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
    "        },\n",
    "    ]),\n",
    "])\n",
    "\n",
    "# prompt for most relevant project selection\n",
    "extract_relevant_project_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'Based on the provided job description, select a project which is most relevant to the roles and responsbilities provided in the job description'),\n",
    "    ('human', [\n",
    "        {'type': 'text', 'text': 'Job description: {job_description} Projects: {projects}. Return the title of the most relevant project'}\n",
    "    ])\n",
    "])\n",
    "def process_resume_with_job_description(resume_images, job_description):\n",
    "    final_result = {}\n",
    "    for image_path in resume_images:\n",
    "        image_data = encode_image(image_path)\n",
    "        resume_data = (resume_prompt | model | parser).invoke({\n",
    "            \"format_instructions\": parser.get_format_instructions(),\n",
    "            \"image_data\": image_data\n",
    "        })\n",
    "    projects = resume_data.projects\n",
    "    if projects:\n",
    "        project_list = '\\n'.join([f'Title: {proj.title}, Outcome: {proj.outcome}, Approach: {proj.approach}' for proj in projects if proj.title])\n",
    "        relevant_project_response = (extract_relevant_project_prompt | model).invoke({\n",
    "                \"job_description\": job_description,\n",
    "                \"projects\": project_list\n",
    "            })\n",
    "        relevant_project_title = relevant_project_response.content.strip()\n",
    "        relevant_project = next((proj for proj in projects if proj.title == relevant_project_title), None)\n",
    "    else:\n",
    "        relevant_project = None\n",
    "\n",
    "    final_result = {\n",
    "        \"personal_info\": resume_data.personal_info.model_dump() if resume_data.personal_info else {},\n",
    "        \"educational_qualifications\": [edu.model_dump() for edu in resume_data.educational_qualifications] if resume_data.educational_qualifications else [],\n",
    "        \"skills\": resume_data.skills if resume_data.skills else [],\n",
    "        \"most_relevant_project\": relevant_project.model_dump() if relevant_project else {}\n",
    "    }\n",
    "\n",
    "    return final_result\n",
    "\n",
    "\n",
    "resume_images = [\"resume/page 1.png\", \"resume/page 2.png\"]\n",
    "\n",
    "\n",
    "final_output = process_resume_with_job_description(resume_images, job_description)\n",
    "print(json.dumps(final_output,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Parsing - PDF as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in document:\n",
    "        text += page.get_text()\n",
    "    document.close()\n",
    "    return text\n",
    "\n",
    "resume_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the resume information in structured JSON format as per the provided schema.\\n'{format_instructions}'\\n\"),\n",
    "    (\"human\", \"Extract structured resume data from this text:\\n\\n{text}\"),\n",
    "])\n",
    "\n",
    "project_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Based on the provided job description, select the most relevant project from the list.\"),\n",
    "    (\"human\", \"Job Description:\\n{job_description}\\n\\nProjects:\\n{projects}\\n\\nReturn the title of the most relevant project.\"),\n",
    "])\n",
    "\n",
    "def process_resume_with_job_description(pdf_path, job_description):\n",
    "    extracted_text = extract_text_from_pdf(pdf_path)\n",
    "    resume_data = (resume_prompt | model | parser).invoke({\n",
    "        \"format_instructions\": parser.get_format_instructions(),\n",
    "        \"text\": extracted_text\n",
    "    })\n",
    "\n",
    "    projects = resume_data.projects\n",
    "    if projects:\n",
    "        project_list = \"\\n\".join([f\"Title: {proj.title}, Outcome: {proj.outcome}, Approach: {proj.approach}\" for proj in projects if proj.title])\n",
    "    \n",
    "        relevant_project_response = (project_prompt_template | model).invoke({\n",
    "            \"job_description\": job_description,\n",
    "            \"projects\": project_list\n",
    "        })\n",
    "        \n",
    "        relevant_project_title = relevant_project_response.content.strip()\n",
    "        relevant_project = next((proj for proj in projects if proj.title == relevant_project_title), None)\n",
    "    else:\n",
    "        relevant_project = None\n",
    "\n",
    "    final_result = {\n",
    "       \"personal_info\": resume_data.personal_info.model_dump() if resume_data.personal_info else {},\n",
    "\"educational_qualifications\": [edu.model_dump() for edu in resume_data.educational_qualifications] if resume_data.educational_qualifications else [],\n",
    "\"most_relevant_project\": relevant_project.model_dump() if relevant_project else {}\n",
    "\n",
    "    }\n",
    "    return final_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = process_resume_with_job_description('resume/cv2.pdf',job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"personal_info\": {\n",
      "        \"name\": \"SPOORTHY S SWAMY\",\n",
      "        \"email\": \"spoorthysswamy@gmail.com\",\n",
      "        \"phone\": \"6362288247\",\n",
      "        \"address\": \"Bangalore, Karnataka\"\n",
      "    },\n",
      "    \"educational_qualifications\": [\n",
      "        {\n",
      "            \"institution\": \"NMKRV College for Women, Jayanagar, Bangalore\",\n",
      "            \"degree\": \"M.Sc. in Data Science\",\n",
      "            \"field_of_study\": null,\n",
      "            \"start_date\": \"2022\",\n",
      "            \"end_date\": \"present\"\n",
      "        },\n",
      "        {\n",
      "            \"institution\": \"The National College, Jayanagar, Bangalore\",\n",
      "            \"degree\": \"B.Sc. in PMC\",\n",
      "            \"field_of_study\": null,\n",
      "            \"start_date\": \"2018\",\n",
      "            \"end_date\": \"2021\"\n",
      "        },\n",
      "        {\n",
      "            \"institution\": \"The Presidency PU College, Sira, Tumkur\",\n",
      "            \"degree\": null,\n",
      "            \"field_of_study\": null,\n",
      "            \"start_date\": \"2016\",\n",
      "            \"end_date\": \"2018\"\n",
      "        },\n",
      "        {\n",
      "            \"institution\": \"The Presidency Public School, Sira, Tumkur\",\n",
      "            \"degree\": null,\n",
      "            \"field_of_study\": null,\n",
      "            \"start_date\": \"2016\",\n",
      "            \"end_date\": null\n",
      "        }\n",
      "    ],\n",
      "    \"most_relevant_project\": {\n",
      "        \"title\": \"Health care chatbot\",\n",
      "        \"outcome\": \"focuses on leveraging advanced ML, NLP and AI technologies to improve early disease detection, provide personalized healthcare guidance, enhance access to care, and support the scalability of healthcare systems, ultimately empowering users to take a more active role in their own health and well-being.\",\n",
      "        \"approach\": null\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Interview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interviewer: So, tell me about your experience working on the healthcare chatbot project.  What was your specific role, and what were some of your key contributions?\n",
      "\n",
      "Interviewer: That's a crucial aspect of building a robust chatbot.  Can you elaborate on a specific challenge you faced during the data cleaning and preprocessing stage, and walk me through your decision-making process in choosing a solution?  I'm particularly interested in the trade-offs you considered.\n",
      "\n",
      "Interviewer: Okay, so you used schema validation to identify missing medical terms. That's a good approach.  Can you explain how you handled those missing values after identifying them? Did you simply remove the entries, impute values, or use a different strategy? And what were the considerations that led to your chosen method – particularly regarding the potential impact on the model's accuracy and the chatbot's overall performance?\n",
      "\n",
      "Interviewer: What specific imputation technique did you choose (e.g., mean, median, mode, k-NN, etc.) and why?  How did you evaluate the impact of your chosen method on the model's performance, and what metrics did you use to assess this impact?\n",
      "\n",
      "Interviewer: Thank you for sharing your insights on this project. Let's proceed to the next part of our interview.\n",
      "Interviewer: So, tell me about your experience working on the healthcare chatbot project.  What was your specific role, and what were some of your key contributions?\n",
      "Candidate: I developed the healthcare chatbot's data processing pipeline, handled JSON data cleaning and preprocessing, and addressed challenges like data inconsistencies and maintaining medical context accuracy.\n",
      "Interviewer: That's a crucial aspect of building a robust chatbot.  Can you elaborate on a specific challenge you faced during the data cleaning and preprocessing stage, and walk me through your decision-making process in choosing a solution?  I'm particularly interested in the trade-offs you considered.\n",
      "Candidate: I encountered missing medical terms in JSON entries, identified them using schema validation\n",
      "Interviewer: Okay, so you used schema validation to identify missing medical terms. That's a good approach.  Can you explain how you handled those missing values after identifying them? Did you simply remove the entries, impute values, or use a different strategy? And what were the considerations that led to your chosen method – particularly regarding the potential impact on the model's accuracy and the chatbot's overall performance?\n",
      "Candidate: I used imputation techniques to fill missing values, ensuring data completeness while monitoring the model's accuracy to avoid compromising the chatbot's performance.\n",
      "Interviewer: What specific imputation technique did you choose (e.g., mean, median, mode, k-NN, etc.) and why?  How did you evaluate the impact of your chosen method on the model's performance, and what metrics did you use to assess this impact?\n",
      "Candidate: KNN\n",
      "Interviewer: Okay, you used KNN imputation.  That's a good choice for handling missing medical terms, as it considers the relationship between data points.  However, KNN can be computationally expensive, especially with large datasets.  Can you describe any performance considerations you had to address when implementing KNN imputation in your data processing pipeline for the healthcare chatbot, and what strategies you employed to mitigate any potential performance bottlenecks?\n"
     ]
    }
   ],
   "source": [
    "def conduct_project_interview(selected_project: Dict[str, Any], job_description: str, max_questions: int = 5) -> Dict[str, Any]:\n",
    "    conversation_history = []\n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert technical interviewer. Generate relevant follow-up questions based on candidate responses using the\n",
    "    'peeling the onion' technique. Focus on techniques used, problem-solving, and project impact. Keep the responses natural and contextual.\n",
    "    Ask one question at a time.\n",
    "    \"\"\"\n",
    "\n",
    "    # initiating the interview - prompt for initial question\n",
    "    initial_prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \n",
    "         \"Project Details: {project_details}\\n\\n\"\n",
    "         \"Job Description: {job_description}\\n\\n\"\n",
    "         \"Generate an initial open-ended question about this project that allows the candidate to explain their role and contribution. \"\n",
    "         \"The question should be conversational and natural.\"\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    # generation - first question\n",
    "    result = (initial_prompt_template | model).invoke({\n",
    "        \"project_details\": json.dumps(selected_project),\n",
    "        \"job_description\": job_description\n",
    "    })\n",
    "    \n",
    "    initial_question = result.content.strip()\n",
    "    conversation_history.append({'role': 'interviewer', 'question': initial_question})\n",
    "\n",
    "    # follow up questions\n",
    "    for i in range(max_questions - 1):\n",
    "        print(f\"\\nInterviewer: {conversation_history[-1]['question']}\")\n",
    "        candidate_response = input(\"Candidate response (or type 'exit' to end): \").strip()\n",
    "        # empty input?\n",
    "        while not candidate_response:\n",
    "            candidate_response = input(\"Please provide a response or type 'exit' to end: \").strip()\n",
    "        if candidate_response.lower() == 'exit':\n",
    "            break\n",
    "        conversation_history.append({\"role\": \"candidate\", \"response\": candidate_response})\n",
    "        # follow up template question\n",
    "        follow_up_prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \n",
    "             \"Project Details: {project_details}\\n\\n\"\n",
    "             \"Job Description: {job_description}\\n\\n\"\n",
    "             \"Previous Conversation:\\n{conversation_history}\\n\\n\"\n",
    "             \"Generate a natural follow-up question that digs deeper into:\\n\"\n",
    "             \"1. Technical challenges and solutions\\n\"\n",
    "             \"2. Decision-making process\\n\"\n",
    "             \"3. Impact and outcomes\\n\"\n",
    "             \"4. Role and responsibilities\\n\\n\"\n",
    "             \"The question should flow naturally from the candidate's last response.\"\n",
    "            ),\n",
    "        ])\n",
    "        # follow up question generation\n",
    "        follow_up_result = (follow_up_prompt_template | model).invoke({\n",
    "            \"project_details\": json.dumps(selected_project),\n",
    "            \"job_description\": job_description,\n",
    "            \"conversation_history\": json.dumps(conversation_history, indent=2)\n",
    "        })\n",
    "        follow_up_question = follow_up_result.content.strip()\n",
    "        conversation_history.append({\"role\": \"interviewer\", \"question\": follow_up_question})\n",
    "\n",
    "    # concluding interview\n",
    "    print(\"\\nInterviewer: Thank you for sharing your insights on this project. Lets proceed to the next part of our interview\")\n",
    "\n",
    "    # output\n",
    "    return {\n",
    "        \"project_name\": selected_project.get(\"title\", \"Unknown Project\"),\n",
    "        \"conversation_history\": conversation_history,\n",
    "        \"total_questions\": len([x for x in conversation_history if x[\"role\"] == \"interviewer\"]),\n",
    "        \"duration\": len(conversation_history)\n",
    "    }\n",
    "\n",
    "\n",
    "selected_project = result.get(\"most_relevant_project\", {})\n",
    "\n",
    "if selected_project:\n",
    "    interview_result = conduct_project_interview(selected_project, job_description)\n",
    "\n",
    "# history\n",
    "    for exchange in interview_result['conversation_history']:\n",
    "        role = 'Interviewer' if exchange['role'] == 'interviewer' else 'Candidate'\n",
    "        print(f\"{role}: {exchange.get('question') or exchange.get('response')}\")\n",
    "else:\n",
    "    print(\"No relevant project found...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
